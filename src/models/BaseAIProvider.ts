import axios, { AxiosInstance } from "axios";
import { Message, AIModel } from "../types";

export abstract class BaseAIProvider {
  protected client: AxiosInstance;
  protected model: AIModel;

  constructor(apiKey: string, baseUrl: string, model: AIModel) {
    this.model = model;
    this.client = axios.create({
      baseURL: baseUrl,
      headers: {
        "Content-Type": "application/json",
      },
      timeout: 300000,
    });

    this.setupAuth(apiKey);
  }

  protected abstract setupAuth(apiKey: string): void;
  protected abstract formatMessages(messages: Message[]): any[];
  protected abstract parseResponse(response: any): string;
  protected abstract parseStreamResponse(chunk: string): string | null;

  async generateResponse(
    messages: Message[],
    systemPrompt?: string
  ): Promise<string> {
    try {
      const formattedMessages = this.formatMessages(messages);
      if (systemPrompt) {
        formattedMessages.unshift({
          role: "system",
          content: systemPrompt,
        });
      }

      // ÂºÄÂèëÊ®°Âºè‰∏ãËæìÂá∫ËØ∑Ê±ÇÂÜÖÂÆπ
      if (process.env.NODE_ENV === "development") {
        console.log(`\nüîµ [${this.model.provider}] Request:`, {
          model: this.model.name,
          messages: formattedMessages.map((m) => ({
            role: m.role,
            content:
              m.content.substring(0, 500) +
              (m.content.length > 500 ? "..." : ""),
          })),
        });
      }

      let response: any;
      let parsedResponse: string;

      try {
        // È¶ñÂÖàÂ∞ùËØïÊµÅÂºèËØ∑Ê±Ç
        if (process.env.NODE_ENV === "development") {
          console.log(`\nüì° [${this.model.provider}] Trying streaming request...`);
        }
        
        response = await this.makeStreamRequest(formattedMessages);
        parsedResponse = await this.handleStreamResponse(response);
        
        if (process.env.NODE_ENV === "development") {
          console.log(`\n‚úÖ [${this.model.provider}] Streaming successful`);
        }
      } catch (streamError: any) {
        // ÊµÅÂºèÂ§±Ë¥•ÔºåÂõûÈÄÄÂà∞ÈùûÊµÅÂºè
        if (process.env.NODE_ENV === "development") {
          console.log(`\n‚ö†Ô∏è  [${this.model.provider}] Streaming failed, falling back to non-streaming:`, 
            streamError.message);
        }
        
        response = await this.makeRequest(formattedMessages);
        parsedResponse = this.parseResponse(response.data);
        
        if (process.env.NODE_ENV === "development") {
          console.log(`\n‚úÖ [${this.model.provider}] Non-streaming successful`);
        }
      }

      // ÂºÄÂèëÊ®°Âºè‰∏ãËæìÂá∫ÂõûÂ§çÂÜÖÂÆπ
      if (process.env.NODE_ENV === "development") {
        console.log(`\nüü¢ [${this.model.provider}] Response:`, {
          content:
            parsedResponse.substring(0, 500) +
            (parsedResponse.length > 500 ? "..." : ""),
          fullLength: parsedResponse.length,
        });
      }

      return parsedResponse;
    } catch (error: any) {
      // ÊèêÂèñÊ†∏ÂøÉÈîôËØØ‰ø°ÊÅØ
      let errorMessage = "Unknown error";

      if (error.code === "ECONNABORTED") {
        errorMessage = "Request timeout";
      } else if (error.response) {
        errorMessage = `HTTP ${error.response.status}: ${error.response.statusText}`;
      } else if (error.message) {
        errorMessage = error.message;
      }

      console.error(`Error with ${this.model.provider}: ${errorMessage}`);
      throw new Error(
        `AI provider ${this.model.provider} failed: ${errorMessage}`
      );
    }
  }

  private async handleStreamResponse(response: any): Promise<string> {
    return new Promise(async (resolve, reject) => {
      let fullContent = '';
      
      try {
        // Ê£ÄÊü•ÊòØÂê¶ÊòØ OpenAI SDK ÁöÑÊµÅÂºèÂìçÂ∫î (AsyncIterable)
        if (response.data && Symbol.asyncIterator in response.data) {
          for await (const chunk of response.data) {
            // OpenAI format
            const openaiContent = chunk.choices?.[0]?.delta?.content;
            // Anthropic format
            const anthropicContent = chunk.delta?.text;
            // Gemini format
            const geminiContent = chunk.candidates?.[0]?.content?.parts?.[0]?.text || chunk.text?.();
            
            const content = openaiContent || anthropicContent || geminiContent;
            if (content) {
              fullContent += content;
            }
          }
          resolve(fullContent);
          return;
        }
        
        // ‰º†ÁªüÁöÑÊµÅÂºèÂìçÂ∫îÂ§ÑÁêÜ (ÈÄÇÁî®‰∫éËá™ÂÆö‰πâÂÆûÁé∞)
        response.data.on('data', (chunk: Buffer) => {
          const lines = chunk.toString().split('\n').filter(line => line.trim());
          
          for (const line of lines) {
            if (line.startsWith('data: ')) {
              const data = line.slice(6);
              if (data === '[DONE]') {
                resolve(fullContent);
                return;
              }
              
              try {
                const parsed = this.parseStreamResponse(data);
                if (parsed) {
                  fullContent += parsed;
                }
              } catch (e) {
                // ÂøΩÁï•Ëß£ÊûêÈîôËØØÔºåÁªßÁª≠Â§ÑÁêÜÂÖ∂‰ªñÂùó
              }
            }
          }
        });
        
        response.data.on('end', () => {
          resolve(fullContent);
        });
        
        response.data.on('error', (error: any) => {
          reject(error);
        });
      } catch (error) {
        reject(error);
      }
    });
  }

  protected abstract makeRequest(messages: any[]): Promise<any>;
  protected abstract makeStreamRequest(messages: any[]): Promise<any>;

  getModel(): AIModel {
    return this.model;
  }
}
